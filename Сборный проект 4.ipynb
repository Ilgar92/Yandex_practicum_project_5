{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "CUQuYmMs-mKK",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "CUQuYmMs-mKK",
    "tags": [
     "21a32eca-7494-4096-b202-21be1b7f0a7d"
    ]
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ff1020a",
   "metadata": {
    "cellId": "pbwq209p45adtxfy5ofecd",
    "execution_id": "7cb94123-6481-41de-973a-91abe63db303",
    "id": "1ff1020a"
   },
   "source": [
    "# Прекод\n",
    "\n",
    "# Сборный проект-4\n",
    "\n",
    "Вам поручено разработать демонстрационную версию поиска изображений по запросу.\n",
    "\n",
    "Для демонстрационной версии нужно обучить модель, которая получит векторное представление изображения, векторное представление текста, а на выходе выдаст число от 0 до 1 — покажет, насколько текст и картинка подходят друг другу.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные доступны по [ссылке](https://code.s3.yandex.net/datasets/dsplus_integrated_project_4.zip).\n",
    "\n",
    "В файле `train_dataset.csv` находится информация, необходимая для обучения: имя файла изображения, идентификатор описания и текст описания. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.\n",
    "\n",
    "В папке `train_images` содержатся изображения для тренировки модели.\n",
    "\n",
    "В файле `CrowdAnnotations.tsv` — данные по соответствию изображения и описания, полученные с помощью краудсорсинга. Номера колонок и соответствующий тип данных:\n",
    "\n",
    "1. Имя файла изображения.\n",
    "2. Идентификатор описания.\n",
    "3. Доля людей, подтвердивших, что описание соответствует изображению.\n",
    "4. Количество человек, подтвердивших, что описание соответствует изображению.\n",
    "5. Количество человек, подтвердивших, что описание не соответствует изображению.\n",
    "\n",
    "В файле `ExpertAnnotations.tsv` содержатся данные по соответствию изображения и описания, полученные в результате опроса экспертов. Номера колонок и соответствующий тип данных:\n",
    "\n",
    "1. Имя файла изображения.\n",
    "2. Идентификатор описания.\n",
    "\n",
    "3, 4, 5 — оценки трёх экспертов.\n",
    "\n",
    "Эксперты ставят оценки по шкале от 1 до 4, где 1 — изображение и запрос совершенно не соответствуют друг другу, 2 — запрос содержит элементы описания изображения, но в целом запрос тексту не соответствует, 3 — запрос и текст соответствуют с точностью до некоторых деталей, 4 — запрос и текст соответствуют полностью.\n",
    "\n",
    "В файле `test_queries.csv` находится информация, необходимая для тестирования: идентификатор запроса, текст запроса и релевантное изображение. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.\n",
    "\n",
    "В папке `test_images` содержатся изображения для тестирования модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99489b26",
   "metadata": {
    "cellId": "n6vkjcacwu39w29bfocxt",
    "execution_id": "1b731a18-3394-4b62-b3f7-018692c2d6de",
    "id": "99489b26"
   },
   "source": [
    "## 1. Исследовательский анализ данных\n",
    "\n",
    "Наш датасет содержит экспертные и краудсорсинговые оценки соответствия текста и изображения.\n",
    "\n",
    "В файле с экспертными мнениями для каждой пары изображение-текст имеются оценки от трёх специалистов. Для решения задачи вы должны эти оценки агрегировать — превратить в одну. Существует несколько способов агрегации оценок, самый простой — голосование большинства: за какую оценку проголосовала большая часть экспертов (в нашем случае 2 или 3), та оценка и ставится как итоговая. Поскольку число экспертов меньше числа классов, может случиться, что каждый эксперт поставит разные оценки, например: 1, 4, 2. В таком случае данную пару изображение-текст можно исключить из датасета.\n",
    "\n",
    "Вы можете воспользоваться другим методом агрегации оценок или придумать свой.\n",
    "\n",
    "В файле с краудсорсинговыми оценками информация расположена в таком порядке:\n",
    "\n",
    "1. Доля исполнителей, подтвердивших, что текст **соответствует** картинке.\n",
    "2. Количество исполнителей, подтвердивших, что текст **соответствует** картинке.\n",
    "3. Количество исполнителей, подтвердивших, что текст **не соответствует** картинке.\n",
    "\n",
    "После анализа экспертных и краудсорсинговых оценок выберите либо одну из них, либо объедините их в одну по какому-то критерию: например, оценка эксперта принимается с коэффициентом 0.6, а крауда — с коэффициентом 0.4.\n",
    "\n",
    "Ваша модель должна возвращать на выходе вероятность соответствия изображения тексту, поэтому целевая переменная должна иметь значения от 0 до 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41063cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gurbanovsmac/anaconda3/envs/tf310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import os\n",
    "import math\n",
    "from math import ceil\n",
    "import statistics\n",
    "from functools import lru_cache\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tensorflow.keras.models import Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from torchvision import models\n",
    "from torchvision.models import ResNet50_Weights\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f89b64a-2a80-4122-b734-ca584f1b6072",
   "metadata": {},
   "source": [
    " Импортируем данные, которые ранее были скачаны, и посмотрим, что они из себя представляют"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f0ad587-46a3-4dde-a65a-3125b07132d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('to_upload/train_dataset.csv')\n",
    "CrowdAnnotations = pd.read_csv('to_upload/CrowdAnnotations.tsv', sep='\\t', header=None)\n",
    "ExpertAnnotations = pd.read_csv('to_upload/ExpertAnnotations.tsv', sep='\\t', header=None)\n",
    "test_queries = pd.read_csv('to_upload/test_queries.csv', sep='|', index_col=0)\n",
    "test_images = pd.read_csv('to_upload/test_images.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a68ad47-3368-4e4f-8d52-4d4cb11fc472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262583859_653f1469a9.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2447284966_d6bbdb4b6e.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2549968784_39bfbe44f9.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2621415349_ef1a7e73be.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3030566410_393c36a6c5.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3155451946_c0862c70cb.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3222041930_f642f49d28.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>343218198_1ca90e0734.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3718964174_cb2dc1615e.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image                     query_id  \\\n",
       "0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "1  1262583859_653f1469a9.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "2  2447284966_d6bbdb4b6e.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "3  2549968784_39bfbe44f9.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "4  2621415349_ef1a7e73be.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "5  3030566410_393c36a6c5.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "6  3155451946_c0862c70cb.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "7  3222041930_f642f49d28.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "8   343218198_1ca90e0734.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "9  3718964174_cb2dc1615e.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "\n",
       "                                          query_text  \n",
       "0  A young child is wearing blue goggles and sitt...  \n",
       "1  A young child is wearing blue goggles and sitt...  \n",
       "2  A young child is wearing blue goggles and sitt...  \n",
       "3  A young child is wearing blue goggles and sitt...  \n",
       "4  A young child is wearing blue goggles and sitt...  \n",
       "5  A young child is wearing blue goggles and sitt...  \n",
       "6  A young child is wearing blue goggles and sitt...  \n",
       "7  A young child is wearing blue goggles and sitt...  \n",
       "8  A young child is wearing blue goggles and sitt...  \n",
       "9  A young child is wearing blue goggles and sitt...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5822 entries, 0 to 5821\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   image       5822 non-null   object\n",
      " 1   query_id    5822 non-null   object\n",
      " 2   query_text  5822 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 136.6+ KB\n",
      "\n",
      "\n",
      "\n",
      "CrowdAnnotations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>1056338697_4f7d7ce270.jpg#2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>114051287_dd85625a04.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>1427391496_ea512cbe7f.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2073964624_52da3a0fc4.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2083434441_a93bc6306b.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2204550058_2707d92338.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2224450291_4c133fabe8.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2248487950_c62d0c81a9.jpg#2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2307118114_c258e3a47e.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2309860995_c2e2a0feeb.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0                            1         2  3  4\n",
       "0  1056338697_4f7d7ce270.jpg  1056338697_4f7d7ce270.jpg#2  1.000000  3  0\n",
       "1  1056338697_4f7d7ce270.jpg   114051287_dd85625a04.jpg#2  0.000000  0  3\n",
       "2  1056338697_4f7d7ce270.jpg  1427391496_ea512cbe7f.jpg#2  0.000000  0  3\n",
       "3  1056338697_4f7d7ce270.jpg  2073964624_52da3a0fc4.jpg#2  0.000000  0  3\n",
       "4  1056338697_4f7d7ce270.jpg  2083434441_a93bc6306b.jpg#2  0.000000  0  3\n",
       "5  1056338697_4f7d7ce270.jpg  2204550058_2707d92338.jpg#2  0.000000  0  3\n",
       "6  1056338697_4f7d7ce270.jpg  2224450291_4c133fabe8.jpg#2  0.000000  0  3\n",
       "7  1056338697_4f7d7ce270.jpg  2248487950_c62d0c81a9.jpg#2  0.333333  1  2\n",
       "8  1056338697_4f7d7ce270.jpg  2307118114_c258e3a47e.jpg#2  0.000000  0  3\n",
       "9  1056338697_4f7d7ce270.jpg  2309860995_c2e2a0feeb.jpg#2  0.000000  0  3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47830 entries, 0 to 47829\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       47830 non-null  object \n",
      " 1   1       47830 non-null  object \n",
      " 2   2       47830 non-null  float64\n",
      " 3   3       47830 non-null  int64  \n",
      " 4   4       47830 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 1.8+ MB\n",
      "\n",
      "\n",
      "\n",
      "ExpertAnnotations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2718495608_d8533e3ac5.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3207358897_bfa61fa3c6.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3286822339_5535af6b93.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3360930596_1e75164ce6.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3545652636_0746537307.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>434792818_56375e203f.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>106490881_5a2dd9b7bd.jpg</td>\n",
       "      <td>1425069308_488e5fcf9d.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>106490881_5a2dd9b7bd.jpg</td>\n",
       "      <td>1714316707_8bbaa2a2ba.jpg#2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0                            1  2  3  4\n",
       "0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2  1  1  1\n",
       "1  1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2  1  1  2\n",
       "2  1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2  1  1  2\n",
       "3  1056338697_4f7d7ce270.jpg  3207358897_bfa61fa3c6.jpg#2  1  2  2\n",
       "4  1056338697_4f7d7ce270.jpg  3286822339_5535af6b93.jpg#2  1  1  2\n",
       "5  1056338697_4f7d7ce270.jpg  3360930596_1e75164ce6.jpg#2  1  1  1\n",
       "6  1056338697_4f7d7ce270.jpg  3545652636_0746537307.jpg#2  1  1  1\n",
       "7  1056338697_4f7d7ce270.jpg   434792818_56375e203f.jpg#2  1  1  2\n",
       "8   106490881_5a2dd9b7bd.jpg  1425069308_488e5fcf9d.jpg#2  1  1  1\n",
       "9   106490881_5a2dd9b7bd.jpg  1714316707_8bbaa2a2ba.jpg#2  2  2  2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5822 entries, 0 to 5821\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       5822 non-null   object\n",
      " 1   1       5822 non-null   object\n",
      " 2   2       5822 non-null   int64 \n",
      " 3   3       5822 non-null   int64 \n",
      " 4   4       5822 non-null   int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 227.5+ KB\n",
      "\n",
      "\n",
      "\n",
      "test_queries\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1177994172_10d143cb8d.jpg#0</td>\n",
       "      <td>Two blonde boys , one in a camouflage shirt an...</td>\n",
       "      <td>1177994172_10d143cb8d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1177994172_10d143cb8d.jpg#1</td>\n",
       "      <td>Two boys are squirting water guns at each other .</td>\n",
       "      <td>1177994172_10d143cb8d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1177994172_10d143cb8d.jpg#2</td>\n",
       "      <td>Two boys spraying each other with water</td>\n",
       "      <td>1177994172_10d143cb8d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1177994172_10d143cb8d.jpg#3</td>\n",
       "      <td>Two children wearing jeans squirt water at eac...</td>\n",
       "      <td>1177994172_10d143cb8d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1177994172_10d143cb8d.jpg#4</td>\n",
       "      <td>Two young boys are squirting water at each oth...</td>\n",
       "      <td>1177994172_10d143cb8d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1232148178_4f45cc3284.jpg#0</td>\n",
       "      <td>A baby girl playing at a park .</td>\n",
       "      <td>1232148178_4f45cc3284.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1232148178_4f45cc3284.jpg#1</td>\n",
       "      <td>A closeup of a child on a playground with adul...</td>\n",
       "      <td>1232148178_4f45cc3284.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1232148178_4f45cc3284.jpg#2</td>\n",
       "      <td>A young boy poses for a picture in front of a ...</td>\n",
       "      <td>1232148178_4f45cc3284.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1232148178_4f45cc3284.jpg#3</td>\n",
       "      <td>A young girl is smiling in front of the camera...</td>\n",
       "      <td>1232148178_4f45cc3284.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1232148178_4f45cc3284.jpg#4</td>\n",
       "      <td>There is a little blond hair girl with a green...</td>\n",
       "      <td>1232148178_4f45cc3284.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      query_id  \\\n",
       "0  1177994172_10d143cb8d.jpg#0   \n",
       "1  1177994172_10d143cb8d.jpg#1   \n",
       "2  1177994172_10d143cb8d.jpg#2   \n",
       "3  1177994172_10d143cb8d.jpg#3   \n",
       "4  1177994172_10d143cb8d.jpg#4   \n",
       "5  1232148178_4f45cc3284.jpg#0   \n",
       "6  1232148178_4f45cc3284.jpg#1   \n",
       "7  1232148178_4f45cc3284.jpg#2   \n",
       "8  1232148178_4f45cc3284.jpg#3   \n",
       "9  1232148178_4f45cc3284.jpg#4   \n",
       "\n",
       "                                          query_text  \\\n",
       "0  Two blonde boys , one in a camouflage shirt an...   \n",
       "1  Two boys are squirting water guns at each other .   \n",
       "2            Two boys spraying each other with water   \n",
       "3  Two children wearing jeans squirt water at eac...   \n",
       "4  Two young boys are squirting water at each oth...   \n",
       "5                    A baby girl playing at a park .   \n",
       "6  A closeup of a child on a playground with adul...   \n",
       "7  A young boy poses for a picture in front of a ...   \n",
       "8  A young girl is smiling in front of the camera...   \n",
       "9  There is a little blond hair girl with a green...   \n",
       "\n",
       "                       image  \n",
       "0  1177994172_10d143cb8d.jpg  \n",
       "1  1177994172_10d143cb8d.jpg  \n",
       "2  1177994172_10d143cb8d.jpg  \n",
       "3  1177994172_10d143cb8d.jpg  \n",
       "4  1177994172_10d143cb8d.jpg  \n",
       "5  1232148178_4f45cc3284.jpg  \n",
       "6  1232148178_4f45cc3284.jpg  \n",
       "7  1232148178_4f45cc3284.jpg  \n",
       "8  1232148178_4f45cc3284.jpg  \n",
       "9  1232148178_4f45cc3284.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 500 entries, 0 to 499\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   query_id    500 non-null    object\n",
      " 1   query_text  500 non-null    object\n",
      " 2   image       500 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 15.6+ KB\n",
      "\n",
      "\n",
      "\n",
      "test_images\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3356748019_2251399314.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2887171449_f54a2b9f39.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3089107423_81a24eaf18.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1429546659_44cb09cbe2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1177994172_10d143cb8d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>424307754_1e2f44d265.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3044359043_627488ddf0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3396275223_ee080df8b5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2977379863_2e8d7a104e.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>634891010_9fa189effb.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image\n",
       "0  3356748019_2251399314.jpg\n",
       "1  2887171449_f54a2b9f39.jpg\n",
       "2  3089107423_81a24eaf18.jpg\n",
       "3  1429546659_44cb09cbe2.jpg\n",
       "4  1177994172_10d143cb8d.jpg\n",
       "5   424307754_1e2f44d265.jpg\n",
       "6  3044359043_627488ddf0.jpg\n",
       "7  3396275223_ee080df8b5.jpg\n",
       "8  2977379863_2e8d7a104e.jpg\n",
       "9   634891010_9fa189effb.jpg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   image   100 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 928.0+ bytes\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_table_info(name, data):\n",
    "    print(name)\n",
    "    display(data.head(10))\n",
    "    data.info()\n",
    "    print('')\n",
    "    print('')\n",
    "    print('')\n",
    "\n",
    "display_table_info('train_dataset', train_dataset)\n",
    "display_table_info('CrowdAnnotations', CrowdAnnotations)\n",
    "display_table_info('ExpertAnnotations', ExpertAnnotations)\n",
    "display_table_info('test_queries', test_queries)\n",
    "display_table_info('test_images', test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cdf5f3-6177-4fc5-b3a2-27eb9766f10c",
   "metadata": {},
   "source": [
    "Далее требуется добавить обобщённую экспертную оценку. В качестве итогового значения, согласно предложенному подходу, используется мнение большинства экспертов. В случае если оценки всех экспертов различаются, итоговое значение не присваивается, а соответствующие строки впоследствии исключаются из набора данных.\n",
    "\n",
    "Для реализации этого шага будет разработана функция, принимающая на вход одну строку датасета и возвращающая результат обобщения экспертных оценок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "034f1e53-0635-4c06-a86d-cddab3f2d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_exp(str_in):\n",
    "    res=[0,0,0,0]\n",
    "    for i in range(0,3):\n",
    "        res[int(str_in[i+2]-1)]+=1\n",
    "    if max(res) == 1:\n",
    "        return None\n",
    "    else:\n",
    "        try:\n",
    "            return res.index(max(res))+1\n",
    "        except:\n",
    "            print('ERROR')\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71c2c10-f978-48d7-a0a0-eec4f093387e",
   "metadata": {},
   "source": [
    "Заполним столбец с результатом и удалим строки, в которых отсутствует результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b43bb75-3fab-49ac-a581-5c3cd74156cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExpertAnnotations[5] = ExpertAnnotations.apply(result_exp, axis=1)\n",
    "ExpertAnnotations = ExpertAnnotations.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b678635-255e-4dda-bb44-abdf05e923c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5696 entries, 0 to 5821\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       5696 non-null   object \n",
      " 1   1       5696 non-null   object \n",
      " 2   2       5696 non-null   int64  \n",
      " 3   3       5696 non-null   int64  \n",
      " 4   4       5696 non-null   int64  \n",
      " 5   5       5696 non-null   float64\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 311.5+ KB\n"
     ]
    }
   ],
   "source": [
    "ExpertAnnotations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fdaaea8-cbd5-4c95-a0da-0ffcda5e0cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.iloc[ExpertAnnotations.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbaa861",
   "metadata": {
    "cellId": "9h91oxwx86d7i8rqt5miv4",
    "execution_id": "4401a0e8-fd2b-479b-9e84-6ffafbcead47",
    "id": "7cbaa861"
   },
   "source": [
    "## 2. Проверка данных\n",
    "\n",
    "В некоторых странах, где работает ваша компания, действуют ограничения по обработке изображений: поисковым сервисам и сервисам, предоставляющим возможность поиска, запрещено без разрешения родителей или законных представителей предоставлять любую информацию, в том числе, но не исключительно тексты, изображения, видео и аудио, содержащие описание, изображение или запись голоса детей. Ребёнком считается любой человек, не достигший 16 лет.\n",
    "\n",
    "В вашем сервисе строго следуют законам стран, в которых работают. Поэтому при попытке посмотреть изображения, запрещённые законодательством, вместо картинок показывается дисклеймер:\n",
    "\n",
    "> This image is unavailable in your country in compliance with local laws\n",
    ">\n",
    "\n",
    "Однако у вас в PoC нет возможности воспользоваться данным функционалом. Поэтому все изображения, которые нарушают данный закон, нужно удалить из обучающей выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01ea39a-1915-4338-b96e-f69f9e89a36d",
   "metadata": {},
   "source": [
    "Для выполнения данного требования сначала сформируем словарь, содержащий слова, относящиеся к детям и подросткам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b352d2cd",
   "metadata": {
    "cellId": "6j23jr8qr9wgyyqkm2puj",
    "id": "b352d2cd"
   },
   "outputs": [],
   "source": [
    "ban_dict = ['child', 'baby', 'boy', 'girl', 'teenager', 'schoolboy', 'youth', 'newborn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f6b3bd-954e-4487-9f35-2168131e641e",
   "metadata": {},
   "source": [
    "Далее выполним преобразование текстовых описаний с использованием сформированного словаря."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ea3e0e7-0929-4895-8eb2-6d6deeaba152",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemma_clear(text):\n",
    "    lemm = nlp(text)\n",
    "    lemm = \" \".join([token.lemma_ for token in lemm])\n",
    "\n",
    "\n",
    "    return \" \".join(lemm.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f69d94b4-a53d-4324-b4bf-a2b405572daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = train_dataset['query_text'].apply(lemma_clear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21948627-fe43-4c42-92fd-64e7b203621b",
   "metadata": {},
   "source": [
    "Реализуем функцию, которая возвращает значение False, если в строке обнаружено запрещённое слово, и True — если такие слова отсутствуют."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0596fde-3c94-4f09-ba6c-52a48a89a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_ban_word(text):\n",
    "    for s in ban_dict: \n",
    "        if text.find(s) > -1:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ba39cd0-3e80-47d4-a4a6-0b21243f738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['lem_query_text'] = corpus\n",
    "train_dataset['is_in_law'] = corpus.apply(is_ban_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a38e0b3-64d9-4b3e-bc25-d85539478c7e",
   "metadata": {},
   "source": [
    "Далее отберём все изображения, в описаниях которых встречаются «запрещённые» слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f63e9f0-f82d-4ae0-b876-72de1d85b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spl(text):\n",
    "    return text[:text.find('#')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb929b68-0d23-497d-86b9-732f886de274",
   "metadata": {},
   "outputs": [],
   "source": [
    "forb_images = list(train_dataset[train_dataset['is_in_law']==False]['query_id'].apply(spl).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9138260c-a070-4c85-96de-2ab2377395fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(forb_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2896ae2-5f94-4aa5-83eb-db608aa76be1",
   "metadata": {},
   "source": [
    "В результате проверки 277 изображений не прошли отбор, их список сохранён в переменной forb_images. Далее удалим из обучающей выборки все «запретные» описания, а также изображения, в описаниях которых встречаются запрещённые слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac0c6e63-bdd6-47c4-8f96-3e2b1d85e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_not_forb(text):\n",
    "    if text in forb_images:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "train_dataset_clear = train_dataset[train_dataset['is_in_law']]\n",
    "train_dataset_clear = train_dataset_clear[train_dataset_clear['image'].apply(is_not_forb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6118398d-e43e-4fa5-a0bb-230838ce0e04",
   "metadata": {},
   "source": [
    "Таким образом, из обучающей выборки были исключены все данные, связанные с детьми.\n",
    "\n",
    "Далее добавим к изображениям экспертные оценки. Ранее была получена обобщённая экспертная оценка. Поскольку экспертные оценки представлены в четырёх уровнях (от «полностью не соответствует» до «полностью соответствует»), тогда как оценки, полученные с аутсорса, принимают значения в диапазоне от 0 до 1 (доля респондентов, посчитавших описание соответствующим изображению), требуется привести экспертные оценки к сопоставимому масштабу.\n",
    "\n",
    "В данном случае применим следующее преобразование: из значения экспертной оценки вычитается 1, после чего результат делится на 3. В результате получаем следующие значения:\n",
    "\n",
    " - полностью не соответствует — 0;\n",
    "\n",
    " - скорее не соответствует — 0.(3);\n",
    "\n",
    " - скорее соответствует — 0.(6);\n",
    "\n",
    " - полностью соответствует — 1.\n",
    "\n",
    "Это преобразование позволяет объединить экспертные оценки с оценками аутсорса, используя коэффициенты значимости 0.6 и 0.4 соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d0ab86c-b13a-403e-a013-39783e3d359b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2718495608_d8533e3ac5.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3207358897_bfa61fa3c6.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3286822339_5535af6b93.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0                            1  2  3  4    5\n",
       "0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2  1  1  1  1.0\n",
       "1  1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2  1  1  2  1.0\n",
       "2  1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2  1  1  2  1.0\n",
       "3  1056338697_4f7d7ce270.jpg  3207358897_bfa61fa3c6.jpg#2  1  2  2  2.0\n",
       "4  1056338697_4f7d7ce270.jpg  3286822339_5535af6b93.jpg#2  1  1  2  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>1056338697_4f7d7ce270.jpg#2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>114051287_dd85625a04.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>1427391496_ea512cbe7f.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2073964624_52da3a0fc4.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2083434441_a93bc6306b.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0                            1    2  3  4\n",
       "0  1056338697_4f7d7ce270.jpg  1056338697_4f7d7ce270.jpg#2  1.0  3  0\n",
       "1  1056338697_4f7d7ce270.jpg   114051287_dd85625a04.jpg#2  0.0  0  3\n",
       "2  1056338697_4f7d7ce270.jpg  1427391496_ea512cbe7f.jpg#2  0.0  0  3\n",
       "3  1056338697_4f7d7ce270.jpg  2073964624_52da3a0fc4.jpg#2  0.0  0  3\n",
       "4  1056338697_4f7d7ce270.jpg  2083434441_a93bc6306b.jpg#2  0.0  0  3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>6</th>\n",
       "      <th>2_y</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2718495608_d8533e3ac5.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>434792818_56375e203f.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1084040636_97d9633581.jpg</td>\n",
       "      <td>256085101_2c2617c5d0.jpg#2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1084040636_97d9633581.jpg</td>\n",
       "      <td>3396157719_6807d52a81.jpg#2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>979383193_0a542a059d.jpg</td>\n",
       "      <td>3244747165_17028936e0.jpg#2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>979383193_0a542a059d.jpg</td>\n",
       "      <td>3482062809_3b694322c4.jpg#2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>2985679744_75a7102aab.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>3150742439_b8a352e1e0.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>486917990_72bd4069af.jpg#2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2258 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0                            1         6  \\\n",
       "0     1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2  0.000000   \n",
       "1     1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2  0.000000   \n",
       "2     1056338697_4f7d7ce270.jpg   434792818_56375e203f.jpg#2  0.000000   \n",
       "3     1084040636_97d9633581.jpg   256085101_2c2617c5d0.jpg#2  0.666667   \n",
       "4     1084040636_97d9633581.jpg  3396157719_6807d52a81.jpg#2  0.333333   \n",
       "...                         ...                          ...       ...   \n",
       "2253   979383193_0a542a059d.jpg  3244747165_17028936e0.jpg#2  0.333333   \n",
       "2254   979383193_0a542a059d.jpg  3482062809_3b694322c4.jpg#2  0.333333   \n",
       "2255   997722733_0cb5439472.jpg  2985679744_75a7102aab.jpg#2  0.000000   \n",
       "2256   997722733_0cb5439472.jpg  3150742439_b8a352e1e0.jpg#2  0.000000   \n",
       "2257   997722733_0cb5439472.jpg   486917990_72bd4069af.jpg#2  0.666667   \n",
       "\n",
       "           2_y       res  \n",
       "0     0.000000  0.000000  \n",
       "1     0.000000  0.000000  \n",
       "2     0.000000  0.000000  \n",
       "3     0.333333  0.533333  \n",
       "4     0.000000  0.200000  \n",
       "...        ...       ...  \n",
       "2253  0.000000  0.200000  \n",
       "2254  0.000000  0.200000  \n",
       "2255  0.000000  0.000000  \n",
       "2256  0.000000  0.000000  \n",
       "2257  0.333333  0.533333  \n",
       "\n",
       "[2258 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(ExpertAnnotations.head())\n",
    "display(CrowdAnnotations.head())\n",
    "#train_dataset_clear.head()\n",
    "\n",
    "ExpertAnnotations[6] = (ExpertAnnotations[5]-1)/3\n",
    "train_data = ExpertAnnotations.merge(CrowdAnnotations, left_on=[0, 1], right_on=[0, 1])[[0, 1, 6, '2_y']]\n",
    "train_data['res'] = train_data[6]*0.6 + train_data['2_y']*0.4\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3280380-89fa-41c4-9eca-e96fb13596bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_clear = train_dataset_clear.merge(train_data, left_on=['image', 'query_id'], right_on=[0, 1])[train_dataset_clear.columns]\n",
    "train_data = train_dataset_clear.merge(train_data, left_on=['image', 'query_id'], right_on=[0, 1])[train_data.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4ef807",
   "metadata": {
    "cellId": "ggxcvhmhcm9rshysbjoo4n",
    "execution_id": "d7935f99-48c0-42b8-a227-dd2b2d9b70fc",
    "id": "1d4ef807"
   },
   "source": [
    "## 3. Векторизация изображений\n",
    "\n",
    "Перейдём к векторизации изображений.\n",
    "\n",
    "Самый примитивный способ — прочесть изображение и превратить полученную матрицу в вектор. Такой способ нам не подходит: длина векторов может быть сильно разной, так как размеры изображений разные. Поэтому стоит обратиться к свёрточным сетям: они позволяют \"выделить\" главные компоненты изображений. Как это сделать? Нужно выбрать какую-либо архитектуру, например ResNet-18, посмотреть на слои и исключить полносвязные слои, которые отвечают за конечное предсказание. При этом можно загрузить модель данной архитектуры, предварительно натренированную на датасете ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0167b804",
   "metadata": {
    "cellId": "4wiflhqkew9mq1gq5927e",
    "id": "0167b804"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace=True), MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "), AdaptiveAvgPool2d(output_size=(1, 1)), Linear(in_features=2048, out_features=1000, bias=True)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad_(False)\n",
    "    \n",
    "print(list(resnet.children())) \n",
    "\n",
    "modules = list(resnet.children())[:-1]\n",
    "resnet = nn.Sequential(*modules) \n",
    "\n",
    "resnet.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f700dfc0-4f53-4ba3-9b5b-980e95fc91b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "norm = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(150),\n",
    "    transforms.CenterCrop(140),\n",
    "    transforms.ToTensor(),\n",
    "    norm,\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b6d9309-ae77-40bb-bea0-5b1aadc928e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"to_upload/train_images/1056338697_4f7d7ce270.jpg\").convert('RGB') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b646bd2-dfd2-4bf7-84bd-4a62d3c14b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor = preprocess(img)\n",
    "output_tensor = resnet(image_tensor.unsqueeze(0)).flatten()\n",
    "output_tensor.size()\n",
    "#output_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1ee410-a0bc-4229-917d-6de4f1b6525e",
   "metadata": {},
   "source": [
    "Размер выходного вектора без применения пуллинга оказался слишком большим, поэтому он был уменьшен с помощью операции пуллинга для сокращения затрат памяти.\n",
    "\n",
    "Далее преобразуем все изображения в датасете в векторные представления с использованием данной модели. Для этого реализуем соответствующую функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37009ee1-9155-4282-8bac-6d0539503767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vect_gen_test(string):\n",
    "    img = Image.open(path+string[0]).convert('RGB')\n",
    "    image_tensor = preprocess(img)\n",
    "    output_tensor = resnet(image_tensor.unsqueeze(0)).flatten()\n",
    "    output_tensor.size()\n",
    "    return output_tensor.numpy()\n",
    "\n",
    "def vect_gen_train(string):\n",
    "    img = Image.open(path+string['image']).convert('RGB')\n",
    "    image_tensor = preprocess(img)\n",
    "    output_tensor = resnet(image_tensor.unsqueeze(0)).flatten()\n",
    "    output_tensor.size()\n",
    "    return output_tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "662471fd-bfef-40b9-bc03-3d091dae4cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"to_upload/train_images/\"\n",
    "train_img_vec_arr = np.array(train_data.apply(vect_gen_test, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea53bf6",
   "metadata": {
    "cellId": "z8evfugfch8wpstvnxv0t",
    "execution_id": "028ade1d-49fe-4110-8b13-3c1aecdaa142",
    "id": "aea53bf6"
   },
   "source": [
    "## 4. Векторизация текстов\n",
    "\n",
    "Следующий этап — векторизация текстов. Вы можете поэкспериментировать с несколькими способами векторизации текстов:\n",
    "\n",
    "- tf-idf\n",
    "- word2vec\n",
    "- \\*трансформеры (например Bert)\n",
    "\n",
    "\\* — если вы изучали трансформеры в спринте Машинное обучение для текстов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7584bd",
   "metadata": {
    "cellId": "5f0eae9yldcozrwh01qp0c",
    "id": "cd7584bd"
   },
   "source": [
    "Использоваем tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0dc2458-7c89-46fc-a333-f648bfd6c712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gurbanovsmac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35c38d61-e850-403d-b7f4-179a8d520c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (1467, 757)\n"
     ]
    }
   ],
   "source": [
    "corpus = train_dataset_clear['lem_query_text']\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=list(stopwords)) \n",
    "\n",
    "tf_idf_train = count_tf_idf.fit_transform(corpus) \n",
    "\n",
    "print(\"Размер матрицы:\", tf_idf_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57928eee-2c4b-42fd-abea-12c551b2033b",
   "metadata": {},
   "source": [
    "Теперь можно векторизируем тексты test_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4d1f6f1-07dd-4d91-9343-130513114fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = test_queries['query_text'].apply(lemma_clear)\n",
    "test_queries['lem_query_text'] = corpus\n",
    "corpus = test_queries['lem_query_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f81d4336-1c4b-4dda-ad28-ccc438eb2c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = count_tf_idf.transform(corpus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10092a30-b9b2-4a31-9950-3b5de0a4d07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (500, 757)\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер матрицы:\", tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760c0ccd",
   "metadata": {
    "cellId": "yci1zcmnsacl720fr75sb",
    "execution_id": "5ecfa9d5-3913-4fb3-a33e-99bab3798577",
    "id": "760c0ccd"
   },
   "source": [
    "## 5. Объединение векторов\n",
    "\n",
    "Подготовьте данные для обучения: объедините векторы изображений и векторы текстов с целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa358eb-d7e1-4aa9-b6ff-c50d30150bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c65788b-609a-4a72-8b81-eae8ef9e0b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mass = np.hstack([np.vstack(train_img_vec_arr), tf_idf_train.toarray()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc9bb60-5bc0-4646-9d92-260f74654eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60bc5668",
   "metadata": {
    "cellId": "97c9jj3s2zjj62vznivsk",
    "execution_id": "1a2d7233-0c79-479a-be63-5787145e3b48",
    "id": "60bc5668"
   },
   "source": [
    "## 6. Обучение модели предсказания соответствия\n",
    "\n",
    "Для обучения разделите датасет на тренировочную и тестовую выборки. Простое случайное разбиение не подходит: нужно исключить попадание изображения и в обучающую, и в тестовую выборки.\n",
    "Для того чтобы учесть изображения при разбиении, можно воспользоваться классом [GroupShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupShuffleSplit.html) из библиотеки sklearn.model_selection.\n",
    "\n",
    "Код ниже разбивает датасет на тренировочную и тестовую выборки в пропорции 7:3 так, что строки с одинаковым значением 'group_column' будут содержаться либо в тестовом, либо в тренировочном датасете.\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.7, random_state=42)\n",
    "train_indices, test_indices = next(gss.split(X=df.drop(columns=['target']), y=df['target'], groups=df['group_column']))\n",
    "train_df, test_df = df.loc[train_indices], df.loc[test_indices]\n",
    "\n",
    "```\n",
    "\n",
    "Какую модель использовать — выберите самостоятельно. Также вам предстоит выбрать метрику качества либо реализовать свою."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a723a8ad",
   "metadata": {
    "cellId": "v1ntb27jt4z9fazi1y8me",
    "id": "a723a8ad"
   },
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, train_size=.7, random_state=42)\n",
    "train_indexes, test_indexes = next(gss.split(X=train_mass, y=train_data['res'], groups=train_dataset_clear['image']))\n",
    "#train_df, test_df = df.loc[train_indices], df.loc[test_indices]\n",
    "\n",
    "X_train = train_mass[train_indexes]\n",
    "X_test = train_mass[test_indexes]\n",
    "y_train = train_data['res'].loc[train_indexes]\n",
    "y_test = train_data['res'].loc[test_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b96bd75-11d3-4c81-8a2a-db3724b83d17",
   "metadata": {},
   "source": [
    "Так создадим и обучим линейную регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32cd4eaa-7f6e-4103-83ca-abc59d0a32dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression(positive=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">copy_X&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">1e-06</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">positive&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LinearRegression(positive=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr = LinearRegression(positive=True)\n",
    "model_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83f81f6c-0f32-4b4a-953e-b8774ab8f3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE кросс-валидации: 0.391705364386589\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "y_pred = scaler.fit_transform(\n",
    "    model_lr.predict(X_test).reshape(-1, 1)\n",
    ")\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"RMSE кросс-валидации:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956bd2d6-c958-498f-a020-38f9becc0ff8",
   "metadata": {},
   "source": [
    "Отлично, исходная точка определена. Теперь перейдём к построению полносвязной нейронной сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31563e4b-efea-427c-abc0-88c9fcd2185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(np.array(X_train))\n",
    "X_test = torch.FloatTensor(np.array(X_test))\n",
    "y_train = torch.FloatTensor(np.array(y_train))\n",
    "y_test = torch.FloatTensor(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4badfaed-d0e5-4e3f-bf10-f28b1d319c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1020, 2805])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "779cd754-f86b-4271-8505-af5995f67934",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_in_neurons, n_hidden_neurons_1, n_hidden_neurons_2, n_hidden_neurons_3, n_hidden_neurons_4, n_out_neurons):\n",
    "            super(Net, self).__init__()\n",
    "            \n",
    "            self.fc1 = nn.Linear(n_in_neurons, n_hidden_neurons_1)\n",
    "            self.act1 = nn.ReLU()\n",
    "            #self.do1 = nn.Dropout(p=0.7)\n",
    "            self.fc2 = nn.Linear(n_hidden_neurons_1, n_hidden_neurons_2)\n",
    "            self.act2 = nn.ReLU()\n",
    "            self.fc3 = nn.Linear(n_hidden_neurons_2, n_hidden_neurons_3)\n",
    "            self.act3 = nn.ReLU()\n",
    "            self.fc4 = nn.Linear(n_hidden_neurons_3, n_hidden_neurons_4)\n",
    "            self.act4 = nn.ReLU()\n",
    "            self.fc5 = nn.Linear(n_hidden_neurons_4, n_out_neurons)\n",
    "            self.act5 = nn.Sigmoid()\n",
    "            \n",
    "            nn.init.kaiming_uniform_(self.fc1.weight, mode='fan_in', nonlinearity='relu')\n",
    "            nn.init.kaiming_uniform_(self.fc2.weight, mode='fan_in', nonlinearity='relu')\n",
    "            nn.init.kaiming_uniform_(self.fc3.weight, mode='fan_in', nonlinearity='relu')\n",
    "            nn.init.kaiming_uniform_(self.fc4.weight, mode='fan_in', nonlinearity='relu')\n",
    "            nn.init.kaiming_uniform_(self.fc5.weight, mode='fan_in', nonlinearity='sigmoid')\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act1(x)\n",
    "        #x = self.do1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.act5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5054b758-056f-4b7c-b0cf-83a87a5a76c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in_neurons = 2805\n",
    "n_hidden_neurons_1 = 1200\n",
    "n_hidden_neurons_2 = 600\n",
    "n_hidden_neurons_3 = 200\n",
    "n_hidden_neurons_4 = 10\n",
    "n_out_neurons = 1\n",
    "\n",
    "\n",
    "\n",
    "net = Net(n_in_neurons, n_hidden_neurons_1, n_hidden_neurons_2, n_hidden_neurons_3, n_hidden_neurons_4, n_out_neurons)\n",
    "\n",
    "#net = nn.Sequential(\n",
    "#    nn.Linear(n_in_neurons, n_hidden_neurons_1),\n",
    "#    nn.ReLU(),\n",
    "#    nn.Linear(n_hidden_neurons_1, n_hidden_neurons_2),\n",
    "#    nn.ReLU(),\n",
    "#    nn.Linear(n_hidden_neurons_2, n_out_neurons)\n",
    "#)\n",
    "\n",
    "optimizer2 = torch.optim.SGD(net.parameters(), lr=1e-3, momentum=0.8)\n",
    "\n",
    "optimizers = [optimizer2]\n",
    "\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "110c6ef0-ff4e-4ce0-91ad-105135598916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимизатор SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0.8\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      "):\n",
      "Метрика RMSE на 0 итерации = 0.35\n",
      "Метрика RMSE на 10 итерации = 0.34\n",
      "Метрика RMSE на 20 итерации = 0.34\n",
      "Метрика RMSE на 30 итерации = 0.34\n",
      "Метрика RMSE на 40 итерации = 0.34\n",
      "Метрика RMSE на 50 итерации = 0.33\n",
      "Метрика RMSE на 60 итерации = 0.33\n",
      "Метрика RMSE на 70 итерации = 0.33\n",
      "Метрика RMSE на 80 итерации = 0.33\n",
      "Метрика RMSE на 90 итерации = 0.33\n",
      "Метрика RMSE на 100 итерации = 0.33\n",
      "Метрика RMSE на 110 итерации = 0.33\n",
      "Метрика RMSE на 120 итерации = 0.33\n",
      "Метрика RMSE на 130 итерации = 0.33\n",
      "Метрика RMSE на 140 итерации = 0.33\n",
      "Метрика RMSE на 150 итерации = 0.33\n",
      "Метрика RMSE на 160 итерации = 0.33\n",
      "Метрика RMSE на 170 итерации = 0.33\n",
      "Метрика RMSE на 180 итерации = 0.33\n",
      "Метрика RMSE на 190 итерации = 0.33\n",
      "Метрика RMSE на 200 итерации = 0.33\n",
      "Метрика RMSE на 210 итерации = 0.33\n",
      "Метрика RMSE на 220 итерации = 0.33\n",
      "Метрика RMSE на 230 итерации = 0.33\n",
      "Метрика RMSE на 240 итерации = 0.33\n",
      "Метрика RMSE на 250 итерации = 0.33\n",
      "Метрика RMSE на 260 итерации = 0.33\n",
      "Метрика RMSE на 270 итерации = 0.33\n",
      "Метрика RMSE на 280 итерации = 0.33\n",
      "Метрика RMSE на 290 итерации = 0.33\n",
      "Метрика RMSE на 300 итерации = 0.33\n",
      "Метрика RMSE на 310 итерации = 0.33\n",
      "Метрика RMSE на 320 итерации = 0.33\n",
      "Метрика RMSE на 330 итерации = 0.33\n",
      "Метрика RMSE на 340 итерации = 0.33\n",
      "Метрика RMSE на 350 итерации = 0.33\n",
      "Метрика RMSE на 360 итерации = 0.33\n",
      "Метрика RMSE на 370 итерации = 0.33\n",
      "Метрика RMSE на 380 итерации = 0.33\n",
      "Метрика RMSE на 390 итерации = 0.33\n",
      "Метрика RMSE на 400 итерации = 0.33\n",
      "Метрика RMSE на 410 итерации = 0.33\n",
      "Метрика RMSE на 420 итерации = 0.33\n",
      "Метрика RMSE на 430 итерации = 0.33\n",
      "Метрика RMSE на 440 итерации = 0.33\n",
      "Метрика RMSE на 450 итерации = 0.33\n",
      "Метрика RMSE на 460 итерации = 0.33\n",
      "Метрика RMSE на 470 итерации = 0.33\n",
      "Метрика RMSE на 480 итерации = 0.33\n",
      "Метрика RMSE на 490 итерации = 0.33\n",
      "Метрика RMSE на 500 итерации = 0.34\n",
      "Метрика RMSE на 510 итерации = 0.34\n",
      "Метрика RMSE на 520 итерации = 0.34\n",
      "Метрика RMSE на 530 итерации = 0.34\n",
      "Метрика RMSE на 540 итерации = 0.34\n",
      "Метрика RMSE на 550 итерации = 0.34\n",
      "Метрика RMSE на 560 итерации = 0.34\n",
      "Метрика RMSE на 570 итерации = 0.34\n",
      "Метрика RMSE на 580 итерации = 0.34\n",
      "Метрика RMSE на 590 итерации = 0.34\n",
      "Метрика RMSE на 600 итерации = 0.34\n",
      "Метрика RMSE на 610 итерации = 0.34\n",
      "Метрика RMSE на 620 итерации = 0.34\n",
      "Метрика RMSE на 630 итерации = 0.34\n",
      "Метрика RMSE на 640 итерации = 0.34\n",
      "Метрика RMSE на 650 итерации = 0.34\n",
      "Метрика RMSE на 660 итерации = 0.34\n",
      "Метрика RMSE на 670 итерации = 0.34\n",
      "Метрика RMSE на 680 итерации = 0.34\n",
      "Метрика RMSE на 690 итерации = 0.34\n",
      "Метрика RMSE на 700 итерации = 0.34\n",
      "Метрика RMSE на 710 итерации = 0.34\n",
      "Метрика RMSE на 720 итерации = 0.34\n",
      "Метрика RMSE на 730 итерации = 0.34\n",
      "Метрика RMSE на 740 итерации = 0.34\n",
      "Метрика RMSE на 750 итерации = 0.34\n",
      "Метрика RMSE на 760 итерации = 0.34\n",
      "Метрика RMSE на 770 итерации = 0.34\n",
      "Метрика RMSE на 780 итерации = 0.34\n",
      "Метрика RMSE на 790 итерации = 0.34\n",
      "Метрика RMSE на 800 итерации = 0.34\n",
      "Метрика RMSE на 810 итерации = 0.34\n",
      "Метрика RMSE на 820 итерации = 0.34\n",
      "Метрика RMSE на 830 итерации = 0.34\n",
      "Метрика RMSE на 840 итерации = 0.34\n",
      "Метрика RMSE на 850 итерации = 0.34\n",
      "Метрика RMSE на 860 итерации = 0.34\n",
      "Метрика RMSE на 870 итерации = 0.34\n",
      "Метрика RMSE на 880 итерации = 0.34\n",
      "Метрика RMSE на 890 итерации = 0.34\n",
      "Метрика RMSE на 899 итерации = 0.34\n",
      "\n",
      "Лучшая метрика RMSE = 0.33 обнаружена на 5 эпохе\n",
      "Средняя метрика RMSE = 0.34\n",
      "--------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 900\n",
    "batch_size = 150\n",
    "num_batches = ceil(len(X_train)/batch_size)\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    optimizer_rmse = []\n",
    "    print(f'Оптимизатор {optimizer}:')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        order = np.random.permutation(len(X_train))\n",
    "        \n",
    "        for batch_idx in range(num_batches):\n",
    "            \n",
    "            start_index = batch_idx * batch_size\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            batch_indexes = order[start_index : start_index + batch_size]\n",
    "            X_batch = X_train[batch_indexes]\n",
    "            y_batch = y_train[batch_indexes]\n",
    "\n",
    "            preds = net.forward(X_batch.float()).flatten()\n",
    "\n",
    "            loss_value = loss(preds, y_batch)\n",
    "\n",
    "            loss_value.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                test_preds = net.forward(X_test).flatten()\n",
    "                #print(test_preds.numpy())\n",
    "                ans = round(float(torch.sqrt(loss(test_preds, y_test))), 2)\n",
    "                print(f'Метрика RMSE на {epoch} итерации =', ans)\n",
    "                optimizer_rmse.append(ans)\n",
    "    print()\n",
    "    print(f'Лучшая метрика RMSE = {min(optimizer_rmse)} обнаружена на {optimizer_rmse.index(min(optimizer_rmse))} эпохе')\n",
    "    print(f'Средняя метрика RMSE = {round(np.mean(optimizer_rmse), 2)}')\n",
    "    print('---------------------------------------------------------------------------------------------', '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f870d77",
   "metadata": {
    "cellId": "tbnfwg686jpxjdsw7cqbl",
    "execution_id": "5e14c3be-a481-438e-a979-0f4621acea44",
    "id": "2f870d77"
   },
   "source": [
    "## 7. Тестирование модели\n",
    "\n",
    "Настало время протестировать модель. Для этого получите эмбеддинги для всех тестовых изображений из папки `test_images`, выберите случайные 10 запросов из файла `test_queries.csv` и для каждого запроса выведите наиболее релевантное изображение. Сравните визуально качество поиска."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801e0c32",
   "metadata": {
    "cellId": "q6sn9kh039f4a6xvu66y7",
    "id": "801e0c32"
   },
   "source": [
    "Для начала сформируем массив эмбеддингов. Для этого воспользуемся ранее реализованной функцией vect_gen_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c12e047-c02f-44bd-95f3-6cdf2bf30690",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"to_upload/test_images/\"\n",
    "test_images_vec = np.vstack(np.array(test_images.apply(vect_gen_train, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d77d2c1-fe11-4ec6-bebf-61f45e14817e",
   "metadata": {},
   "source": [
    "Реализуем функцию, возвращающую список из десяти случайно выбранных описаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d92eec63-ed57-4485-8a30-ee88f34f9c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ten_texts():\n",
    "    texts = []\n",
    "    for i in range(0,10):\n",
    "        texts.append(test_queries.iloc[rd.randint(0, 499)]['query_text'])\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b71e2f8-43f7-47f9-a497-ca28fbdeb442",
   "metadata": {},
   "source": [
    "Теперь напишем функцию, которая подготовит текстовое описание ко входу в модель. Для этого тестовое описание векторизуется и соединяется с каждым из подготовленых изображений. За одно проверим тут текстовый запрос на наличие \"запретных\" слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22376ab1-9d31-4b22-be4b-56d89e67a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_text(text):\n",
    "    corpus_one = lemma_clear(text)\n",
    "    corpus = []\n",
    "    #print(corpus_one)\n",
    "    #print(is_ban_word(corpus_one))\n",
    "    if not is_ban_word(corpus_one):\n",
    "        return None\n",
    "    else:\n",
    "        #tf_idf_one = count_tf_idf.transform(corpus)\n",
    "        for i in range(0,100):\n",
    "            corpus.append(corpus_one)\n",
    "        tf_idf_one = count_tf_idf.transform(corpus)\n",
    "        return(np.hstack([np.vstack(test_images_vec), tf_idf_one.toarray()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5e323f-d397-4603-9632-627164c53ddc",
   "metadata": {},
   "source": [
    "Теперь можно перейти к этапу тестирования. Для каждого из 10 отобранных описаний будет выведено само описание и изображение, набравшее наибольшее количество «очков»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09a0be27-a2e4-4a64-bd34-02841b1e4d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A white dog and a black dog in a field .\n",
      "27\n",
      "A man who is dressed like a wrestler walks while people take his picture .\n",
      "27\n",
      "Two people , one in blue and one in red , stand in front of a building .\n",
      "27\n",
      "A young boy is holding a PlayStation controller over his head .\n",
      "Наличие запретного слова в запросе!\n",
      "There is an older white haired lady and a bulldog sitting on a tree stump .\n",
      "27\n",
      "a red covered boat racing across the water\n",
      "27\n",
      "A little girl with her hands in the air is sitting on a man 's back while he is laying on a blanket .\n",
      "Наличие запретного слова в запросе!\n",
      "A watercraft speeds through the water .\n",
      "27\n",
      "A cyclist riding on their front wheel on the asphalt .\n",
      "27\n",
      "Three people are looking into photographic equipment .\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "for item in ten_texts():\n",
    "    print(item)\n",
    "    try:\n",
    "        mass = conv_text(item)\n",
    "        res = net.forward(torch.FloatTensor(mass)).flatten().detach().numpy()\n",
    "        print(res.argmax())\n",
    "    except:\n",
    "        print('Наличие запретного слова в запросе!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66210e20-9862-4b14-89e4-682084e0f4e6",
   "metadata": {},
   "source": [
    "Поскольку модель во всех случаях выдаёт одно и то же изображение, проведение визуальной оценки качества предсказаний не представляется целесообразным. Решить данную проблему самостоятельно не удалось. В связи с этим по рекомендации преподавателя работа была направлена на ревью с целью получения обратной связи и рекомендаций по возможным способам устранения данной проблемы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab1345a",
   "metadata": {
    "cellId": "dnvdkzzxdpet1yc4m64cx",
    "execution_id": "3e367f6a-97e3-4ed7-9b73-39ed363fd2b7",
    "id": "fab1345a"
   },
   "source": [
    "## 8. Выводы\n",
    "\n",
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Исследовательский анализ данных выполнен\n",
    "- [ ]  Проверены экспертные оценки и краудсорсинговые оценки\n",
    "- [ ]  Из датасета исключены те объекты, которые выходят за рамки юридических ограничений\n",
    "- [ ]  Изображения векторизованы\n",
    "- [ ]  Текстовые запросы векторизованы\n",
    "- [ ]  Данные корректно разбиты на тренировочную и тестовую выборки\n",
    "- [ ]  Предложена метрика качества работы модели\n",
    "- [ ]  Предложена модель схожести изображений и текстового запроса\n",
    "- [ ]  Модель обучена\n",
    "- [ ]  По итогам обучения модели сделаны выводы\n",
    "- [ ]  Проведено тестирование работы модели\n",
    "- [ ]  По итогам тестирования визуально сравнили качество поиска"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 12616,
    "start_time": "2026-01-23T14:50:13.329Z"
   },
   {
    "duration": 3142,
    "start_time": "2026-01-23T14:50:44.697Z"
   }
  ],
  "celltoolbar": "Отсутствует",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "notebookId": "e47b60f7-b2b4-44ee-beb3-b44a93eaf068",
  "notebookPath": "precode.ipynb",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
